
어제 공부를 1도 못했다.
심각하다. 컨디션 조절을 못하고 있다. 야간 업무의 영향이 이리 클줄은 몰랐다.

대책을 세워야 한다. 지금은 30일 새벽 12시이다.
(전날 11시 10분에 neetcode hard difficulty problem 하나 푸느라고 이시간이 되었다.)


진행하기 전에 Java 에서 도대체 HotSpot 이 뭔지를 알아야 한다.

## Hotspot

-> How Hotspot is related to JVM,?

### What is HotSpot ?

https://stackoverflow.com/questions/16568253/difference-between-jvm-and-hotspot

JVM 는 Java virtual machine , 즉 Java 를 가지고 동작하는 virtual machine 이다.

Virtual Machine 이라는 '컨셉' 은, 진짜 물리적 컴퓨터를 모방하는 가상의 기계를 말한다.
진짜 물리적으로 존재하는 컴퓨터처럼 가상 머신도 그 나름대로의 명령어 셋, 아키텍쳐 그리고 execution model 이 있음.
그리고 이 가상머신은 그 고유의 명령어 set 를 가지고 작성된 코드를 실행 가능. 
마치 물리적 기계가 코드를 실행하는 것처럼.

그리고 Hotspot 은 JVM , 즉 Java virtual machine 의 구현체임. 그러니까 Java virtual machine 이라는 것은,
오라클에서 정한 Java 로 동작하는 virtual machine 이라는 컨셉을 말하는 것이고,
HotSpot 은 그걸 구현한 것으로 볼 수 있음.

JVM specification 을 구현한 다른 것으로는 JRockit, IBM J9 등이 있음 
(그러니까 핫스팟이 이런것들 중 하나라는 것. 이것들이 HostSpot의 비교대상. 핫스팟은 JVM 의 구현체 중 하나.)

그리고 OpenJDK 는 "HotSpot"을 포함해서 JDK(Java Development Kit)를 
이루는 여러 컴포넌트(예: 컴파일러, API, 각종 툴 등)를 오픈소스로 개발하는 프로젝트.

그리고 **Eclipse Temurin(Java Version)** 역시 OpenJDK 프로젝트의 소스를 기반으로 만들어지는, 오픈소스 JDK 배포판 중 하나.
여기서 Temurin이 제공하는 자바 런타임의 JVM 구현체는 **HotSpot**입니다.

즉, Temurin(Java by Adoptium)은 OpenJDK의 공식 오픈소스 소스를 바탕으로 
HotSpot JVM과 모든 JDK 컴포넌트를 빌드해서 패키징하여 무료로 제공한다.

Temurin 은 패키징 및 테스트, 빌드 인프라 관리만 하고 소스코드는 그냥 OpenJDK 것을 가져옴.
여러 운영체제용으로 빌드.


---


4주차 공부 [[250928]] 에 이어서...
## How the JIT compiler boosts Java performance in OpenJDK

https://developers.redhat.com/articles/2021/06/23/how-jit-compiler-boosts-java-performance-openjdk#how_a_jit_compiler_works

### HotSpot's JIT execution model

HotSpot JVM 의 execution model 은 여러가지의 관찰로 인한 결과물인데, 어떤 관찰들이냐면...

- Most code is only executed uncommonly, so getting it compiled would waste resources that the JIT compiler needs.
-> 여기서 'uncommonly' 라는 말은, 자주실행 되지 않는, 을 의미한다.
그러니까 code which is executed commonly 는, 자주 실행되는 코드를 의미.

대부분의 코드들은 자주 실행되는 것이 아니기 때문에, 이걸 모두 다 컴파일하는 것은 JIT compiler 가 필요로 하는
자원들을 낭비하는 꼴이 됨.

- 특정 메서드의 subset 만 자주 실행됨

- interpreter 는 어떤 코드든 바로 실행할 준비가 되어 있음.

- 컴파일된 코드는 실행이 빠르지만, 만드는데 리소스를 많이 소모하고,
  시간이 많이 걸리는 컴파일 과정이 끝나야 비로소 실행이 가능함.


#### Multi-tiered execution

Hotspot 에서는, 인터프리터가 자신이 실행하는 코드를 계측 (instrument) 한다.
즉, 각 메서드별로 그 메서드가 몇 번 진입(호출) 되었는지를 카운팅 한다는 뜻.

그리고 '핫' 한 (자주 호출되는) 메소드는 보통 루프를 가지고 있어,  (for, while 등의)
루프 내에서 시작점으로 다시 분기 (branch) 되는 횟수도 같이 집계함.

메서드가 진입할때마다, 인터프리터는 진입횟수 + 루프분기 횟수를 더해 그 합이 특정 임계치를 넘으면
JIT 컴파일 대기열에 해당 메서드를 올림 (컴파일 요청 대기 대상)

그리고 자바 코드를 실행중인 스레드와 별도로, 컴파일러 전용 스레드가 이 컴파일 요청을 처리함.

그리고 컴파일이 진행되는 와중에도 인터프리터는 계속 나머지 코드들을 실행.

컴파일이 완료되면 (즉 실행이 빠른 형식의 코드), 인터프리터는 그 시점부터
해당 메소드에 대해서 컴파일된 코드로 분기해서 실행을 전환 -> 속도 최적화


그래서 인터프리터 : 빠르게 실행되지만 느리게 수행
컴파일 코드 : 시작은 느리지만 (컴파일때문에), 실행은 빠른 (최적화된).

이 둘 사이에 trade-off , 즉 절충이 생긴다 (the trade-off os roughly between...)


컴파일 코드가 얼마나 "느리게 시작"할지는 어느 정도 가상머신 설계자가 조절할 수 있다.

- 컴파일러를 덜 최적화하면, 코드의 실행 시작시간 (얼마나 빠르게 먼저 실행할지) 는 빠를 순 있어도
  성능이 느려진다. (즉, 코드 실행 시작부터 마무리까지의 시간이 늘어남)
- 컴파일 과정을 더 최적화하도록 설계하면 진짜 빠른 코드 (성능이 좋은) 가 만들어지지만, 
  그만큼 해당코드를 실행을 시작하기가 느려짐. 


그래서 이러한 요소들을 고려해 밸런스를 잡기 위해서 (최적의 성능을 위해) Hotspot 은 멀티티어 시스템을 채택,
실행 빈도/상황에 따라 최적화 정도가 다른 여러 컴파일 단계를 구성하는 것.
(코드를 분석하여 컴파일의 최적화정도를 달리함.)

#### The three tiers of execution

핫스팟의 인터프리터, Quick Compiler, Optimizing compiler 로 구성.

그래서 JVM 의 실행흐름은,

먼저 인터프리터에서 실행 시작 (성능은 떨어지나 바로 실행됨)
-> 메서드가 살짝 warm 해지면
(즉, 메소드의 빈도수가 늘어나면)
-> Quick compiler 가 해당 매소드를 컴파일 대기열에 추가, Quick compiler 가 컴파일,
나중에 해당 메소드를 재실행할때 JVM 의 실행흐름이 이렇게 컴파일된 코드를 실행하는 것으로 변경

-> 코드 진행이 계속되면서 quick compiler 에 올라와있던 메소드의 호출 빈도가 더 높아지면 (getting hot)
-> Optimizing compiler의 대기열에 추가 및 컴파일 진행
-> 퀵 컴파일러로 컴파일된 코드를 실행하다가 컴파일 완료되면
-> 해당 메소드에 대한 JVM 의 실행 흐름을 optimizing compiler 가  compile 한 코드로 전환

각 단계에서 메서드의 진입/반복 횟수를 계측하여 'hotspot' 을 판별
method 가 hot 해진 시점이 오면, (threadhold, 임계치를 넘으면) 컴파일 요청을 다음티어로 넘김


역사적으로, c1 (두번째 티어) 는 클라이언트 컴파일러,
c2 (최적화 티어) 는 서버 컴파일러라고 불림.

실제 구현에서는 컴파일러 스레드가 과도하게 요청받지 않도록 컴파일 트리거 임계치도 고정이 아니고,
두번째 계층 (quick compiler) 는 세부계층 (subtier) 으로 나뉜다. (3개로 나뉘는듯)


```java
$ java -XX:+PrintCompilation HelloWorld
     50    1       3       java.lang.Object::<init> (1 bytes)
     50    2       3       java.lang.String::hashCode (55 bytes)
     51    3       3       java.lang.String::indexOf (70 bytes)
     51    4       3       java.lang.String::charAt (29 bytes)
     51    5     n 0       java.lang.System::arraycopy (native)   (static)
     52    6       3       java.lang.Math::min (11 bytes)
     52    7       3       java.lang.String::length (6 bytes)
     52    8       3       java.lang.AbstractStringBuilder::ensureCapacityInternal (27 bytes)
     52    9       1       java.lang.Object::<init> (1 bytes)
     53    1       3       java.lang.Object::<init> (1 bytes)   made not entrant
     55   10       3       java.lang.String::equals (81 bytes)
     57   11       1       java.lang.ref.Reference::get (5 bytes)
     58   12       1       java.lang.ThreadLocal::access$400 (5 bytes)
Hello world!
```

여기서 좌측의 3번째 숫자, 3 3 3 3 등은 컴파일러의 티어 (tier) 이머 1~3은 저수준 (quick compiler), 
4는 고수준 최적화 컴파일러. (optimizing compiler)



### Deoptimization and Speculation

quick compiled code 또는 optimizing compiled code 에서 첫번째 단계, interpreter 수준으로 돌아가 메서드가 실행되는 경우가 있음
-> Deoptimization

coner case, 즉 null 체크, 드문 타입 분기 (메소드 호출 뿐만 아니라 반복문의 시작점까지 hotspot jvm 은 측정한다고 위에 나와있음),
예상치 못한 클래스 로딩등의 코드 부분에서는, 컴파일된 코드에서는 실제로,
interpreter 로 해당 코드 실행 등으로 intepreter 로 실행 수준을 낮추게 된다.

#### Deoptimization 하는 이유

##### complexity, safety

corner case 까지 모두 대비해 컴파일러가 코드를 만들어버리면 전체 코드가 너무 복잡해지고, 느려짐.
그래서 이런 케이스의 경우 thread 가 deoptimize 하고 인터프리터로 돌아가(switch) 안전하게 실행시키는 전략 사용.

이렇게 하면 컴파일러를 간단히 구현, 그리고 예외 상황도 안전하게 처리 가능.

##### speculation

두번째 이유이자 가장 중요한 이유. Deoptimization 덕분에 JIT compiler 가 '추측' 할 수 있다는 것
(deoptimization allows the JIT compilers to speculate). 

각 JIT compiler 가 추측을 할때 (즉, compiling level 을 상승시킬지) 정확하게 예측대로 될거라는 보장은
현실적으로 없다.
만약 compile 된 코드대로 JVM 이 실행하다가 corner case 가 나오거나 예상과는 다른 반응이 나올때,
우리는 deoptimization을 하면 된다. (예외 상황이 발생하면)

즉 deoptimization 함으로써 JIT compiler 는 공격적으로 speculate 할 수 있는 것이다.
(공격적 speculation -> accelerate performance)


### Synchronous and asynchronous deoptimization

C2 compiler 에서는, speculation 이라는 기법이 다양하게 활용됨.

interpreter, 그리고 quick compiler 등은 실제 실행중에
타입체크, 분기, 메소드 호출 횟수등으로부터 데이터를 모으고, C2 compiler 는 이 데이터를 바탕으로
speculation 함.

이런 예시들을 봤을때 (여기선 내용 스킵) deoptimization 에는 2가지 종류가 있음. (요청 주체에 따라 나뉨)

#### synchronous deoptimization

컴파일된 코드를 실행하는 thread 가 직접 요청

-> C2 compiler 가 여기선 null 이 안나올거야, 하고 가정하고 null check 를 생략한 코드를 컴파일된 코드에 포함.
-> 실제 실행중에 null 이 들어오면, 해당 코드를 실행중인 스레드가 deoptimization 요청.

-> HotSpot 용어로써 이를 uncommon trap 이라고 부름.

#### asynchronous deoptimization

컴파일된 코드를 실행하는 thread 가 아닌 외부 thread 에서 deoptimization 요청.

C2 compiler 가 '이 클래스에는 서브 클래스가 없을거야' 라고 가정하고, 
가상 메서드 호출을 직접 호출로 최적화. (서브클래스의 오버라이딩이 없을거라고 예측)

나중에 다른 스레드가 새로운 서브클래스를 로드하면, 그 사실을 감지한 JVM 이
해당 메서드의 컴파일 코드를 deoptimization 대상으로 표시 (safe point 설정)

이 메서드를 실행 중이던 스레드는 다음에 safe point 에 도달하면 deoptimization 발생


### Safepoints and deoptimization

deoptimization이 발생하면, JVM 은 실행상태를 복원해서 인터프리터가
해당 메서드에서 정확히 같은 지점에서 실행을 이어나갈 수 있게끔 해야 하며, 따라서 safepoint 에는 
인터프리터 상태 (지역변수 등) 와 컴파일된 코드내에서의 위치 (레지스터, 스택 등) 이 존재함.

synchronous optimization 의 경우 deopimization이 발생할때 실행 지점에 safepoint 생성.

최적화 과정에서 컴파일러는 실행속도를 높이기 위해 연산순서를 자주 바꾼다.
(-> 이래서 thread safe 하지 않은 변수에 대해서 memory visibility 가 보장되지 않을 수 있음 )

이때 이런 연산 재배치가 safe point 너머로 설정되는 것은 당연히 금지됨.

모든 바이트코드에 대해서 safe point 를 설정할 수 있음. 연산재배치의 이유때문이기도 하고, 최적화 때문이기도 하고.
따라서 컴파일시에 반환, 호출, 루프 등 일부 지점에만 safe point 를 설정하고, deoptimization 이 너무 늦어지지 않으면서도
컴파일러가 safepoint 사이에서 자유롭게 최적하 할 수록 균형을 맞춤.

이는 가비지 컬렉션, 기타 VM 작업에도 영향을 미침.
예를들어, 가비지 컬렉션은 스레드 스택에 살아있는 객체의 위치 정보를 필요로 하는데, 이 정보는 오직
safe point 에서만 얻을 수 있음.

일반적으로, 컴파일된 코드에서는 safepoint 만이 vm 이 작업할 수 있는 상태정보를 제공하는 유일한 위치임.


## Map.Entry

3주차 공부 [[250922]] 에 이어서

From neetcode top-k-elements solution
[[250922 needcode top-k-elements]]

```java
public int[] topKFrequent(int[] nums, int k) {  
  
    int[] answer = new int[k];  
  
    Map<Integer, Integer> map = new HashMap<>();  
    for (int i=0; i<nums.length; i++) {  
        int x = nums[i];  
        map.merge(x, 1, Integer::sum);  
    }  
  
    List<Integer> sorted = map.entrySet()
						.stream()
						.sorted(
							Map.Entry.<Integer, Integer>comparingByValue()
								.reversed()
								)  
					    .map(Map.Entry::getKey)  
					    .toList();            // 수정
  
    for (int i=0; i<k; i++) {  
        answer[i] = sorted.get(i);  
    }  
    return answer;  
}
```

```java

1. map -> Map <Integer, Integer> 

2. map.entrySet() -> Set<Map.Entry<K, V>> 
   (Map.entrySet)
   
3. stream() -> Stream<Entry<Integer, Integer>>
   (Set.stream)

4. Map.Entry.<Integer, Integer>comparingByValue().

5. Stream.sorted()
```


### 다시 Map.Entry.<Integer, Integer>comparingByValue() 로 돌아와서...

^cb018f

즉, Entry interface 는 Map 의 inner interface 로 정의되어 있고,
comparingByValue 는 Entry interface 의 static method 인 것.


```java
public static <K, V extends Comparable<? super V>> Comparator<Map.Entry<K, V>> comparingByValue() {  
    return (Comparator<Map.Entry<K, V>> & Serializable)  
        (c1, c2) -> c1.getValue().compareTo(c2.getValue());  
}
```
-> 실제로 static 으로 선언되어 있다.



