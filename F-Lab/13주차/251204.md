

## 엔티티 매니저

JPA 에서 DB 랑 통신하는 창구 + 1차 캐시 (persistence context) 를 들고 있는  API -> "interface"
엔티티들을 CRUD 하고, 그 엔티티들이 속한 persistence context 를 관리함.

그리고 이 persistence context 에 동일 엔티티를 한개만 유지한다 (identity 보장)
그리고 flush 시점에 INSERT/UPDATE/DELETE 같은 걸 함.


- 동일 엔티티?
-> 자바 객체가 다르면 (메모리 상으로.)
(첫번째 : instance identity -> a == b (memory location, 즉 물리적으로 실제로 같은 인스턴스인지)
두번째 : instance equality -> a.equals(b) (also called equality by value, 즉 값이 같으면 같은 객체라는 것)) -> 여기서 첫번째

그래서 새로 생성한 2객체는 save 될때 서로 다른 엔티티로써 db 에 저장되며, 그 리턴값의 id 는 다르다.

그런데 만약

```java
Reservation res = reservationRepository.findById(10)
Reservation res2 = reservationRepository.findById(10)
```

이래버리면 두 변수는 완전히 같은 자바 객체 인스턴스를 가리킨다.

하나의 엔티티 = 하나의 레코드.


### 하는 일

엔티티 라이프 사이클 관리

### Hibernate 에서의 객체의 상태


네가지이며, 각 상태는 persistence context 와 어떤 관계나로 정의된다.

- transient 
자바 앱에서 new 생성자로 만들었지만, 어떤 EntityManager (persistence context) 에도 등록되지 않은 상태.
DB row 와 연결도 없고, Hibernate 가 전혀 모르는 객체.

- persistent
EntityManager 가 관리 중인 상태. persistent context 안에 등록된 엔티티 인스턴스.
em.persist(r), em.find(Reservation.class, id) 또는 JPQL 등으로 조회된 객체를 말함.

EntityManager 에 의해 관리




중요한게, 책에서는 엔티티의 정의를
@Entity 어노테이션이 붙은 클래스의 모든 인스턴스를 엔티티로 정의한다는 것이다.

이는 자바에서의 객체 - 인스턴스와는 개념이 조금 다르다.
그러니까 동일한 클래스의 같은 값을 가진 서로 다른 java 객체 (주소가 다름) 에 대해서는 모두
transient 엔티티이며, 이 중에 하나가 'save' 되고 나면,




### 객체, snapshot, 레코드

객체를 새로 new 로 만들면, 당연히 Hibernate 입장에선 모르고 persistence context 에 등록이 되지 않은 상태.
이 상태를 transient 상태라고 한다.





### persistence context 와 EntityManager

Entity Manager 를 만들면 내부에 persistence context 가 하나 생성되고, EntityManager 를 닫으면 context 도 닫힘

persistence context 는 이 작업 (작업 하나당 entitymanager 1개 생성) 단위 동안 관리되는 모든 persistent 엔티티를 추적하고,
그 변경 사항을 db 에 동기화 하는 서비스 이자, 1차 캐시 (first level cache).

하나의 persistence context 안에서는 같은 row 에 대해 항상 하나의 엔티티 인스턴스만 존재하고, 더티체킹을 위해 스냅샷을 유지함.

그러니까 EntityManager 는 외부에서 보는 API 이며, 외부에게 find, persist, remove, flush 등의 메서드를 재공.

내부적으로는 자기 전용 persistence context 를 가지고 있음.
이 persistent context 가 엔티티 인스턴스와 각 엔티티의 스냅샷을 관리함. 

그리고 entitymanager 를 통해 flush 를 호출하면, persistent context 가 dirty checking 을 수행해
insert/update/delete 를 생성한다.


### 팩토리 ? -> EntityManagerFactory

- 각 팩토리는 자기 전용 Entity Manager 인스턴스들을 만들 수 있다.

어플리케이션에서 공유되는 엔트리 포인트 ?
-> 프로세스 전체에서 하나 만들어두고 모두가 같이 쓰는 출입구 객체

왜 엔트리 포인트라고 부르냐면, Spring App 이 Hibernate 를 통해 db 작업을 하기 위해서는 Entity Manager 가 필요한데,
이를 만드는게 EntityManagerFactory 이기 때문이다.

그래서 “EntityManagerFactory﻿ 는 persistence unit 에 대한 설정과 매핑을 보유하고, 
거기서 EntityManager﻿ 를 생성하는 애플리케이션의 시작점(entry point)”라고 설명하는 것.

-> EntityManagerFactory 가 만들어질때, persistence unit 에 대한 설정과 매핑을 보유하면서 생성된다.

- `Persistence.createEntityManagerFactory("HelloWorldPU")`를 호출하면, JPA 구현체(Hibernate)가 
  `persistence.xml`에서 `"HelloWorldPU"`라는 `<persistence-unit>` 블록을 찾는다.​


하나의 factory 에는 entity manager 가 여러개 생성되며 그게 정상이다.
EntityManagerFactory 는 비싸면서 thread-safe 하고, EntityManager 는 싸지만 non-thread-safe 하며,
하나의 비즈니스 작업 (unit of work) 에서 한번 쓰리고 버리는 객체.

그래서 트랜잭선 / http 요청마다 entity manager 하나 쓰는게 일반적.'

그래서 EntityManagerFactory 는 싱글톤.

#### persistence unit

- persistence unit 에 적힌 것들은
	-  어떤 엔티티 클래스들이 이 유닛에 속하는지
    
	- 어떤 DataSource/JDBC URL, 드라이버, 계정 정보를 쓸지
	    
	- 어떤 Hibernate/JPA 옵션(DDL 전략, 캐시 설정 등)을 쓸지

즉 persistence unit 은 엔티티 매핑 정보와 db 연결 설정, 그리고 여러 설정 프로퍼티를 묶어놓은 하나의 논리적 단위.


이런 설정 + 엔티티 매핑 정보를 전부 읽어서 메타데이터로 만들고 그걸 팩토리에 저장함.

- “`EntityManagerFactory`가 생성될 때, 해당 persistence unit 의 설정과 엔티티 매핑 정보를 읽어서 내부에 보유한다.
    
- 그 이후 애플리케이션에서 DB 작업을 시작할 때마다, 
  이 팩토리에서 `EntityManager`를 만들어 쓰므로, 이 팩토리가 JPA/Hibernate 쪽으로 들어가는 시작점(entry point) 역할을 한다.”

##### 언제 어떻게 생성되나

코드에서 `Persistence.createEntityManagerFactory("HelloWorldPU")` 처럼 부르는 순간, JPA 구현체(Hibernate)가 `persistence.xml` 에서 이름이 `"HelloWorldPU"` 인 `<persistence-unit>` 블록을 읽고, 그 설정으로 EntityManagerFactory﻿ 를 만든다


##### 한 어플리케이션에서 여러개 있을 수 있나

가능하다. 여러개 쓰는 이유는 서로 다른 db 에 붙어야 할떄. -> db 마다 persistence unit 하나씩.
같은 db 라도 다른 설정 쓰고 싶을때.



####  엔티티 매핑 정보 
어떤 엔티티 클래스/필드가 DB 의 어떤 테이블/컬럼에 대응되는지에 대한 정보이다.
  레코드 하나의 값이 아니라, 클래스/필드 <-> 테이블/컬럼 구조를 연결해 놓은 메타데이터.


즉, 
“property 를 들고 있는 게 EntityManagerFactory﻿ 이고, 애플리케이션이 DB 작업을 시작할 때마다 그 팩토리로부터 EntityManager﻿ 가 새로 생성된다.




## 책을 그냥 읽어야 겠다. AI 와의 대화로는 답이 안나온다. 다시 Java Persistence with Hibernate

### JPA 
-> Java 에서 ORM (Object-Relation Mapping) 을 표준화한 스펙 + 그 스펙에 나오는 API 묶음.

JPA는 다음을 표준화한 명세 (Specification)다.​

- 어떤 클래스를 엔티티로 볼지, 어떤 필드를 컬럼으로 매핑할지 정하는 애노테이션들
	예: @Entity, @Id, @ManyToOne, @OneToMany 등은 전부 javax.persistence 패키지에 있는 표준 메타데이터다.​

- 엔티티를 저장/조회/수정/삭제하고 persistence context 를 관리하는 API
	예: EntityManager, EntityManagerFactory, Query, TypedQuery 같은 인터페이스들이 여기에 포함된다.​

- 엔티티를 대상으로 하는 객체지향 쿼리 언어와 그 API
	예: JPQL, Criteria API 등.​

persistence.xml 로 persistence unit 설정하는 방법, 트랜잭션과 어떻게 엮이는지 등 아키텍처 레벨 규칙들.​

그리고 

### Hibernate
-> 그걸 구현한 것.

다른 구현체로는 EclipseLink. 이런 라이브러리등이 JPA 스펙을 구현한 ORM 구현체라 볼 수 있음.


### Spring Data JPA
-> JPA 위에 얹은 추상화 레이어. 순수 JPA 보다 덜 번거롭게 쓰라고 만든 것.

- 뭐가 더 쉬워졌냐
	-> Repository 인터페이스만 정의하면 구현 클래스를 안 써도 된다.
	-> JpaRepository<User, Long> 같은 인터페이스만 만들면 기본 CRUD(save, findById, delete 등)를 다 제공한다.​
	-> 메서드 이름으로 쿼리를 자동 생성해준다.
	-> findByEmail, findByStatusAndCreatedAtAfter 같은 메서드 이름만 지으면 JPQL 을 자동으로 만들어 실행해준다.​
	-> save 가 내부에서 persist/merge 를 알아서 분기한다.

Spring Data 문서에도 CrudRepository.save(…) 가 “새 엔티티면 entityManager.persist(...), 아니면 entityManager.merge(...)를 호출한다”고 명시돼 있다.​

- 결국 JPA랑 무슨 관계냐

JPA(정확히는 EntityManager, 매핑 애노테이션 등)는 그대로 쓴다.

다만 Spring Data JPA 가 그 위에 Repository 추상화, 자동 구현,
쿼리 메서드, 페이징·정렬 같은 편의 기능을 얹어서 “데이터 접근 레이어 구현에 필요한 코드를 최소화”하는 게 목표라고 공식 설명한다.​

### 엔티티 정의하는 법


![[Screenshot 2025-12-04 at 10.12.31 AM.png|600]]

모든 persistent entity class 는 반드시 @id 어노테이션으로 표시되는 identifier attiribute 가 필요하다.

그리고 Hibernate 는 위에 text 필드를 'TEXT' 컬럼과 맵핑한다.


### 엔티티 저장하기

ManagerFactory 를 먼저 만든다.
(Thread safe, 그리고 db를 사용하는 코드들은 모두 이걸 공유해야 함)

![[Screenshot 2025-12-04 at 10.16.20 AM.png|700]]

트랜잭션을 따온다
-> 트랜잭션을 시작한다
-> entity manager 를 생성한다
-> persistet 하고 하자는 객체를 생성한다

-> em 으로 persist 한다.

-> tx.commit 한다.
여기서
```sql
INSERT INTO MESSAGE (ID, TEXT) values (1, 'Hello World!')
```
실행이 된다.

-> em.을 닫는다



## Chapter 3 Domain models


- 도메인 
-> 어플리케이션이 풀고 싶은 문제 영역

- 도메인 모델 
-> 도메인을 이해하기 위한 개념/객체 모델.
	필요한 대상들의 개념,속성, 관계를 정의한 것


### cardinality of association

두 엔티티(클래스) 사이에 몇 대 몇 관계인지를 숫자로 표현 한 것

cadinality / multiplicity 
하나의 User 는 여러개의 Order 를 가진다고 했을때
User쪽은 1, Order 쪽은 0..*


![[Screenshot 2025-12-04 at 10.53.36 AM.png|600]]

" enfoce the cardinality " 즉 몇대몇 관계인지를 강제한다 라고 표현하기도 함.

이건 지금 중요한 내용이 아닌 것 같다


파트 2에서는 mapping 을 어떻게 가져갈것인지에 대한 '전략' 에 대한 내용임


# Questions

## ACID

### Atomicity

일련의 동작들을 하나의 트랜잭션으로 묶었을때,
이 일련의 동작들이 모두 성공하거나, 아니면 중간에 하나라도 실행되지 못했을때 모두 적용되지 않는
All or nothing 의 성질을 갖는 것을 말한다. 중간 상태를 가지지 않는 것을 의미한다.


### Consistency

데이터들의 관계나 의미, 논리적인 구성이 깨지지 않는 것.
트랜잭션이 시작하기 전과 후에 DB 의 제약조건이 깨지지 않는 것을 의미함.
예를 들면, 이커머스에서 어떠한 사용자가 있고 그 사용자가 주문한 것에 대한 여러 주문 정보들이 있을 것이다.

그런데 트랜잭션이 실행이 되고 난 다음에, 어떤 사용자의 주문정보가 해당 주문을 실질적으로 진행한 사람을 가리키는게 아니라 
전혀 다른 사람의 주문정보라고 저장이 된다면 이건 논리적 흐름이 깨진 것.


### isolation

트랜잭션이 동시에 여러개 실행될때,  실행 자체는 병렬적으로 되어도, 
각 트랜잭션이 마치 자신만 단독으로 실행된 것처럼 보이게 하는 성질.
즉 결과가 어떤 트랜잭션들을 어떤 순서로 하나씩 실행한 것과 동일할때 isolation 이 보장된다고 할 수 있다.

#### anomalies

#####  dirty read

커밋 되지 않은 데이터를 읽는 것

#####  non-repeatable read

하나의 트랜잭션 T 에서 같은 row 를 두번 읽었는데
그 사이에 다른 트랜잭션에 해당 row 를 업데이트해서 
첫번째 읽은 것과 두번째 읽은게 다른 현상을 말함.

->phantom read 와는 달리 하나의 레코드에 대한 값이 달라지는 것을 의미

##### phantom read

R(id, value)
	초기: (1, 10), (2, 20)

T1: step1: SELECT * FROM R WHERE value > 15 → (2) 하나

T2: INSERT INTO R VALUES (3, 30) 후 commit

T1: step2: 같은 쿼리 다시 → (2), (3) 두 개

즉 하나의 트랜잭션에서 서로 다른 select 사이에
읽어진 record의 수 또는 구성이 달라지는 경우 ( 2, 3 -> 1, 3 이런식오 바뀐거니까)

#### 격리 수준

예시 ->  재고 : 10
t1 : 재고를 읽고 3개를 팔아서 7 로 업데이트 한다
t2 : 재고를 읽고 재고 대로 똑같이 주문을 한다.


##### READ UNCOMMITTED

커밋되지 않은 데이터를 읽는것을 허용한다. ( = dirty read )

t1 트랜잭션 시작 : 재고 를 3개 팔아서 7개로 업데이트 (아직 트랜잭션 안끝남)
t2 : 재고7개 그대로 똑같이 주문
t1 : 롤백, 재고는 10

결과 : 재고는 10개, 주문도 10개가 되어야 하는데 7개가 주문.


##### READ COMMITTED
dirty read 방지, non-repeatable read 가능

항상 '커밋'된 된 값만 읽는다.
하지만, 같은 트랜잭션 안에서 같은 row 를 두번 읽으면,
그 사이에 다른 트랜잭션이 해당 레코드를 commit 해서 값이 바뀔 수 있음 (non-repeatable read)

t1 시작 : t1 read -> 10
t2 시작 : t2 read -> 10

t1 write -> 7 (update)
(이 사이에 t2 가 값을 읽을 순 없음)
t1 commit -> 7

t2 read again -> 7

##### REPEATABLE READ
non-repeatable read 방지, phantom 가능

트랜잭션이 한 번 읽은 row는 그 트랜잭션 안에서 다시 읽을 때 언제나 같은 값이 보인다.

그래서 non-repeatable read는 없다.

하지만 “조건에 맞는 row 집합(여러 row)”을 읽을 때는 새 row가 끼어들어 phantom이 생길 수 있다.

먼저 “non-repeatable read가 막히는” 예시부터:

	초기: X = 10
	
	T1, T2 시작 (같은 데이터 X를 다룸)
	
	T2 (REPEATABLE READ): read(X) → 10
	
	T1이 변경 후 커밋
	
	T1: read(X) → 10
	
	T1: write(X) → 7
	
	T1: commit
	
	T2가 다시 X를 읽음
	
	T2: read(X) → 10 (여전히 10을 본다, 트랜잭션 시작 시점의 값으로 고정)
	
	결과:
	
	T2 입장에서는 X가 처음부터 끝까지 10으로 보임
	
	non-repeatable read 없음.
	
	-> 처음 읽었던 값을 그대로 읽으므로, 스냅샷 개념이 사실상 필요함. 아님 버전의 개념이나.
	근데 대신에 구성 (record 개수나 그 구성) 은 달라질 수 있음


phantom read 상황 예시

	데이터:

	재고 테이블 Items(id, stock)
	
	초기: (1, 5), (2, 5) → stock > 3 인 row는 2개
	
	T1 (REPEATABLE READ):
	
	SELECT COUNT(*) FROM Items WHERE stock > 3 → 결과 2
	
	T2:
	
	INSERT INTO Items(id=3, stock=5)
	
	commit
	
	T1이 같은 조건으로 다시 조회
	
	SELECT COUNT(*) FROM Items WHERE stock > 3 → 결과 3
	
	결과:
	
	같은 조건 WHERE stock > 3 으로 두 번 조회했는데 결과가 2 → 3으로 바뀜
	
	이미 존재하던 row의 값이 바뀐 게 아니라 “새 row가 끼어든” 현상 → phantom read.



#####  SERIALIZABLE

모든 anomaly 제거

동시에 돌더라도, 결과만 보면 “어떤 순서로 일렬로 실행한 것과 완전히 같은 상태”만 허용.

dirty / non-repeatable / phantom 모두 안 됨.

충돌 나면 한 트랜잭션을 실패시키는 식으로라도 이 성질을 유지.

같은 재고 예시:

초기: X = 10

T1: X에서 3개 빼기 (X = X − 3)
T2: X에서 3개 빼기

논리적으로 가능한 serial 실행:

순서 A: T1 → T2
T1: X 10 → 7
T2: X 7 → 4

최종 X = 4

순서 B: T2 → T1
T2: X 10 → 7
T1: X 7 → 4
최종 X = 4

serializable예시)

T1, T2 동시에 시작

T1: read(X) → 10

T2: read(X) → 10

둘 다 “X=10이니까 3개 빼도 된다”고 판단

두 개의 write가 충돌한다고 간주

시스템이 둘 중 하나(T2)를 롤백하거나 재시도 요구

결국 남는 실행은 “T1만 성공 후 T2 재시도” 또는 반대

전체 결과는 A 또는 B 중 하나와 같아짐 → serializable.



### Durability

시스템이 꺼져도 데이터가 남아있는 속성.
더 엄밀히 얘기하자면 트랜잭션이 commit 이 된 이후에는
시스템에 문제가 생겨도 그 결과가 영구적으로 보존되는 성질을 의미함.

## ALU - 컴퓨터에서 왜 나눗셈은 느릴까?

일단 멘토님이 글에 쓰신건 사람이 하는 나눗셈. (long division)
컴퓨터는 실제로 좀 다르다.


### ALU 에서 나눗셈을 구현하는 방식


$$ R:=N;\hspace{0.2cm} while R≥D \hspace{0.5cm} do \hspace{0.2cm}R:=R−D $$

13 - 2 = 11 (몫 = 1)
11 -2 = 9 (몫 = 2)
...
3 - 2 = 1 (몫 = 6)

-> 13 / 2 는 6 , 나머지는 1

근데 실제론 최적화된 기법을 사용하는데
shift + subtract (= restoring), non-restoring division 등이 있음

restoring division 스타일을 보면

- 알고리즘

A : accumulator -> partial remainder
Q : quotient register
M : divisor register 

1. (A, Q) 를 한 덩어리처럼 왼쪽으로 1 비트 shift
2. A = A - M
3. A 가 음수면 A = A + M 으로 되돌리고, Q 의 LSB = 0
	음수가 아니면 Q 의 KSB = 1
	-> 이걸 비트수만큼 반복

비트가 5일때

M = 3 -> 00011 
Q = 13 -> 01101
A = 00000

AQ 를 쉬프트 -> 00000 11010
A = A - M -> 0 - 00011 -> 0  + 11101 -> 11101
음수이므로 다시 되돌림 -> 11101 + 00011 -> 00000, Q = 11010

00001 10100
1  + 11101 -> 11110 
음수이므로 다시 되돌림 -> A = 00001, Q = 10100

00011 01000
A = 11 + 11101 -> 00000
음수가 아니므로 A = 0,  Q = 01001

그래서 나눗셈이 느린 이유는
쉬프트 동작 + 뺄셈 + 덧셈을 하거나 안하거나 + LSB 설정
이러한 일련의 동작이 비트수만큼 동작하기 떄문

참고로 쉬프트는 하드웨어에서 나눗셈처럼 복잡한 반복 알고리즘 안 거치고,  
그냥 비트 위치만 한 번에 밀어버리는 단순 회로라 훨씬 싸다


## 왜 Atomicty 를 구현하기가 어려운가 ?

CPU 의 ALU 의 add 와 같은 한 연산은 atomic 하기가 간단하지만,
왜 DB 의 Atomicty 을 이루기가 힘든가?




