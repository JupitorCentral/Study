
# `currentTimeMillis` 와 `nanoTime` 을 이용해서 측정하더라도 정확한 결과가 나오지 않을 수도 있다. 성능을 측정할 때 어떤 점이 이렇게 노이즈를 만들어내는걸까?

일단 Java 의 JIT 동작에 따른 warm up 으로 처음과 나중에 차이가 크게 난다.

자바에서 코드가 실행된다는 것은 결국 프로세스/스레드가 컴퓨터의 CPU 스케줄링 알고리즘에 따라 선택이 되야 이루어지는 것이다.
그리고 이 알고리즘은 매 순간마다 다르게 동작할 수 밖에 없다. 결과가 일정하지 않다. 
하나의 컴퓨터에서는 수많은 프로스세/스레드들이 실행되기 때문이다.

측정 도중 gc 가 발생할 수도 있다.

최신 CPU 에서는 전력을 아끼기 위해 클럭속도를 조절한다.
부하가 걸리면 클럭을 높이고, 부하가 없거나 부하로 인한 열이 지나친 경우 낮추는 식으로.
이런 경우에도 실행시간 자체가 달라진다.


이러한 문제를 해결하기 위해 JMH 를 쓰는게 좋다.
JMH 는 웜업을 미리해준다. GC 가 간섭하지 않도록 제어한다.
여러번 돌려서 통계적으로 유의미한 결과를 보여준다 -> OS 에 덜 의존적이도록.


# `currentTimeMillis` vs. `nanoTime`

nanoTime은 실행이 시작한 시점부터 '흐른 시간' 을 측정한다.
currentTImeMillis 는 실행되는 컴퓨터의 '현재 시간' 을 측정한다.

문제는 이 현재 시간이라는 것이 갑자기 달라질 수 있다는 것.
서버에서 NTP (Network Time Protocol) 을 통해 시간을 동기화하면 시간이 갑자기 점프할 수 있다.

클라우드에 서버가 있는 경우 가상 머신의 물리적인 위치가 변할때
새로운 호스트 서버의 시간을 받아오면서 측정된 currentTimeMills 가 갑자기 변할 수 있다.

그리고 currentTimeMillis 는 운영체제에 따라 업데이트 주기가 다르다.
mac 이나 Linux 는 보통 1ms 로 정확하지만 Windows 의 경우에는 15.6 ms 단위로 갱신된다.

그리고 단위가 밀리세컨드와 나노세컨드이므로
정밀한 측정, 프로파일링에는 nanoTIme 이 적합.

그리고 currentTimeMillis 는 OS 커널을 거쳐 윤년, 표준시 변환등의 계산을 할 수 있다.
반면 nanoTime 은 구현체마다 다르긴하지만 일반적으로 CPU 에서 RDTSC (Read Time-Stamp Counter) 같은 하드웨어 명령어를 사용한다.
그래서 추가적인 계산이 없는 nanoTime 실행은 오버헤드가 덜하기때문에 외부 요인에 영향을 덜받는다.




# `Collections.synchronizedMap` vs `ConcurrentHashMap` 왜 ConcurrentHashMap가 더 빠를까?

둘의 차이점 : 락의 범위가 다르다.

`Collections.synchronizedMap` : 맵 객체 자체에 단 하나의 락을 건다.
get, put, remove 든 무조건 mutex 객체 하나를 획득해야 한다.

반면에 `ConcurrentHashMap` 은 일단 읽기에는 락이 없다. volatile 키워드를 이용해 쓰기작업이 진행중이어도 읽기를 허용함.

쓰기도 객체 자체를 잠구지 않는다. 2가지 케이스가 있는데
1. 먼저 해쉬계산된 공간에 데이터를 쓸때 비어있는 경우 CAS (Compare-and-swap)이라는 연산을 통해 (이 연산이 원자적이다) 데이터를넣음
2. 만약 해쉬계산된 공간에 이미 데이터가 있다면 그 칸의 첫번째 노드 객체 하나에 대해서만 synchronized 를 건다.
   (linked list 얘기하는 것으로 이해)
   그래서 다른 버켓은 자유롭게 쓸 수 있음




# 왜 리플렉션은 비용이 많이 나갈까?


## 1. JIT 컴파일러의 최적화 불가 (No JIT Optimization)

가장 결정적인 이유입니다.  
일반적인 메서드 호출은 JIT(Just-In-Time) 컴파일러가 **인라인(Inlining)** 최적화를 수행합니다. 쉽게 말해, 메서드를 호출하는 코드를 메서드 내용 자체로 바꿔치기해서 호출 비용을 '0'으로 만듭니다.

하지만 리플렉션은 런타임에 동적으로 클래스와 메서드를 찾습니다. JIT 컴파일러 입장에서는 "얘가 지금 무슨 메서드를 부를지 도저히 모르겠네?" 상태가 되어 **최적화를 포기합니다.**

> "Because reflection involves types that are dynamically resolved, certain Java virtual machine optimizations can not be performed. Consequently, reflective operations have slower performance..."
> 
> _"리플렉션은 동적으로 해결되는 타입을 포함하기 때문에, 특정 JVM 최적화를 수행할 수 없습니다. 결과적으로 리플렉션 작업은 비리플렉션 작업보다 성능이 느립니다..."_
> 
> _Oracle Java Documentation - Reflection_[](https://docs.oracle.com/javase/8/docs/api/java/lang/System.html)​

## 2. 타입 체크와 보안 검사 (Type & Security Checks)

우리가 `method.invoke()`를 호출할 때마다 JVM은 의심이 많아서 매번 검사를 수행합니다.

1. **접근 제어 검사 (Access Control):** "이 메서드가 `private`인가?", "호출할 권한이 있는가?"를 매번 확인합니다. (`setAccessible(true)`를 해도 비용이 완전히 사라지진 않습니다.)
    
2. **파라미터 검증:** "네가 넘긴 인자가 이 메서드가 원하는 타입이 맞나?"를 확인하고, 맞다면 **Boxing/Unboxing** (예: `int` -> `Integer`) 과정을 거칩니다.
    

> "Reflection requires additional security checks, which add to the execution time. ... each reflective call requires access and type verification that significantly degrade performance."
> 
> _"리플렉션은 추가적인 보안 검사를 요구하며, 이는 실행 시간을 증가시킵니다. ... 각 리플렉션 호출은 접근 및 타입 검증을 필요로 하여 성능을 크게 저하시킵니다."_
> 
> _PVS-Studio Blog, Codemia_[](https://pvs-studio.com/en/blog/posts/java/1266/)​

## 3. 클래스 메타데이터 조회 (Dynamic Resolution)

코드를 직접 짜면 컴파일러가 "아, 이 메서드는 메모리 주소 0x1234에 있어"라고 딱 정해줍니다.  
하지만 리플렉션은 실행 중에 **"잠시만요, 이름이 'getName'인 메서드가 어디 있더라..."** 하고 클래스 로더(Class Loader)를 뒤져서 메타데이터를 찾아야 합니다. 도서관에서 책 위치를 외우고 가는 것과, 가서 검색대에서 찾는 것의 차이입니다.[](https://stackoverflow.com/questions/435553/java-reflection-performance)​